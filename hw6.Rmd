---
title: "hw6"
author: "Brennan Baker"
date: "November 26, 2018"
output:
  github_document:
    toc: true
---
# Problem 1

```{r load packages}
library(tidyverse)
library(forcats)
library(modelr)
library(mgcv)
```

### Load and tidy data

```{r load and tidy data}
homicides_df = read_csv(file = "./data/data-homicides-master/homicide-data.csv")

homicides_df = homicides_df %>% 
  mutate(city_state = str_c(city, ",\ ", state)) %>% 
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) %>% 
  mutate(victim_age = as.numeric(victim_age)) %>% 
  filter(!is.na(victim_age)) %>% 
  filter(victim_race != "unknown") %>% 
  mutate(victim_race = ifelse(victim_race == "White", "white", "non-white")) %>% 
  mutate(victim_race = as.factor(victim_race)) %>% 
  mutate(victim_race = relevel(victim_race, ref = "white")) %>% 
  mutate(resolution = factor(ifelse(
    disposition %in% c("Closed without arrest", "Open/No arrest"), "unresolved", "resolved")))
```

After importing the data, I created a city_state variable. I excluded cities that have errors or do not report race. I converted age to numeric and removed NA age rows. I filtered out unknown race and recoded race as white or non-white, with white as the reference group. I removed unknown race because if the race is unknown, we cannot know if race is white or non-white. I recoded the disposition variavle as solved or unsolved. 

### Baltimore model

```{r baltimore fit}
baltimore_fit = homicides_df %>%
  filter(city_state == "Baltimore, MD") %>% 
  glm(resolution ~ victim_age + victim_race + victim_sex, data = ., family = binomial())
```

The above code saves a logistic regression to baltimore_glm. The model uses victim age, race, and sex to predict whether the case is resolved or unresolved.

```{r odds ratio}
baltimore_fit %>% broom::tidy(conf.int = TRUE) %>% 
  mutate(OR = exp(estimate),
         conf.low = exp(conf.low),
         conf.high = exp(conf.high)) %>% 
  select(term, OR, conf.low, conf.high) %>% 
  filter(term == "victim_racenon-white") %>% 
  knitr::kable(digits = 3)
```

The above table shows the estimate and confidence interval of the odds ratio for resolved vs unresolved homicides predicted by race, controling for age and sex.

### Models for all cities

```{r all cities fit, warning = FALSE}
homicides_models = homicides_df %>% 
  group_by(city_state) %>% 
  nest() %>% # now we have a list col called data containing all the data for each city state
  mutate(model = map(data, ~broom::tidy(glm(resolution ~ victim_age + victim_race + victim_sex, data = ., family = binomial()), conf.int = TRUE))) %>%
  select(-data) %>% 
  unnest() %>%
  mutate(OR = exp(estimate),
         conf.low = exp(conf.low),
         conf.high = exp(conf.high)) %>% 
  select(city_state, term, OR, conf.low, conf.high) %>%
  filter(term == "victim_racenon-white")

homicides_models %>% knitr::kable(digits = 3)
```

The above code uses a map function to run the model that we used with baltimore on each city_state.

```{r}
homicides_models %>% 
  mutate(city_state = forcats::fct_reorder(city_state, OR)) %>%
  ggplot(aes(x = city_state, y = OR)) + 
      geom_point() +
      geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
      labs(
        x = "City, State",
        y = "Odds Ratio",
        title = "Odds homicide remains unsolved if non-white compared to white") +
      theme_bw() +
      theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

The above plot shows that Boston is the US city with the largest discrepancy in homicide resolutions between white and non-white victims. In Boston, non-white victim homicides are 8.7 times as likely to remain unresolved compared to white victim homicides.

# Problem 2

### Load and tidy data

```{r load and tidy birthweight data}
birthweight_df = read_csv(file = "./data/birthweight.csv")

birthweight_df = birthweight_df %>% 
   mutate(
      babysex = as.factor(babysex),
      frace = as.factor(frace),
      malform = as.factor(malform),
      mrace = as.factor(mrace))
```

The code above loads the data and converts sex, mother's race, father's race, and birth malformation into factor variables.

```{r missing data}
birthweight_df %>% 
  is.na() %>% summary()
```

From the code above we see that there is no missing data

### Propose model

```{r models}
lin_mod1 = lm(bwt ~ delwt + mrace, data = birthweight_df)
lin_mod2 = lm(bwt ~ delwt + frace, data = birthweight_df)
lin_mod3 = lm(bwt ~ delwt + mrace + frace, data = birthweight_df)
lin_mod4 = lm(bwt ~ delwt + mrace*frace, data = birthweight_df)

broom::tidy(lin_mod1)
broom::tidy(lin_mod2)
broom::tidy(lin_mod3)
broom::tidy(lin_mod4)
```

I want to see how race of the parents affects birthweight. The above code creates 4 models, one with mother's race, one with father's race, one with both factors, and one with both factors and their interaction.


```{r training data}
cv_df = 
  crossv_mc(birthweight_df, 100)
```

The above code uses modelr to do 100 training/testing splits on the birthweight_df. 

```{r run models on training data, warning = FALSE}
cv_df = 
  cv_df %>% 
  mutate(lin_mod1 = map(train, ~lm(bwt ~ mrace, data = .x)),
         lin_mod2 = map(train, ~lm(bwt ~ frace, data = .x)),
         lin_mod3 = map(train, ~lm(bwt ~ mrace + frace, data = .x)),
         lin_mod4 = map(train, ~lm(bwt ~ mrace*frace, data = .x))) %>% 
  mutate(rmse_lin1 = map2_dbl(lin_mod1, test, ~rmse(model = .x, data = .y)),
         rmse_lin2 = map2_dbl(lin_mod2, test, ~rmse(model = .x, data = .y)),
         rmse_lin3 = map2_dbl(lin_mod3, test, ~rmse(model = .x, data = .y)),
         rmse_lin4 = map2_dbl(lin_mod4, test, ~rmse(model = .x, data = .y)))
```

The above code fits the 4 proposed models and gets RMSEs

```{r proposed model plot}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

From the above plots, we see that the full model with mother's race, father's race, and the interaction was the best model because on average, it produced the lowest RMSEs when run with 100 training datasets.

### Plot residuals and predictions


```{r pred and resid plot}
resid = modelr::add_residuals(birthweight_df, lin_mod4)
resid_and_pred = modelr::add_predictions(resid, lin_mod4)

resid_and_pred %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  labs(
    title = "Model",
    x = "Predictions",
    y = "Residuals"
    ) 
```
show a plot of model residuals against fitted values â€“ use add_predictions and add_residuals in making this plot.

### Compare proposed model to Jeff's models

```{r compare to jeffs models, warning = FALSE}

cv_df2 = 
  crossv_mc(birthweight_df, 100)

cv_df2 = 
  cv_df2 %>% 
  mutate(lin_mod5 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         lin_mod6 = map(train, ~lm(bwt ~ blength*bhead*babysex, data = .x)),
         proposed_mod = map(train, ~lm(bwt ~ mrace*frace, data = .x))) %>% 
  mutate(rmse_mod5 = map2_dbl(lin_mod5, test, ~rmse(model = .x, data = .y)),
         rmse_mod6 = map2_dbl(lin_mod6, test, ~rmse(model = .x, data = .y)),
         rmse_proposed = map2_dbl(proposed_mod, test, ~rmse(model = .x, data = .y)))

cv_df2 %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

From the plot above we see that the best model has head circumference, length, sex, and all interactions (model 6).