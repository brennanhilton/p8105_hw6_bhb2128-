---
title: "hw6"
author: "Brennan Baker"
date: "November 26, 2018"
output:
  github_document:
    toc: true
---

```{r include = FALSE}
knitr::opts_chunk$set(warning = FALSE)
```


# Problem 1

```{r load packages}
library(tidyverse)
library(forcats)
library(modelr)
library(mgcv)
```

### Load and tidy data

```{r load and tidy data}
homicides_df = read_csv(file = "./data/data-homicides-master/homicide-data.csv", na = c("", "NA", "Unknown"))

homicides_df = homicides_df %>% 
  mutate(city_state = str_c(city, ",\ ", state)) %>% 
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) %>% 
  mutate(victim_age = as.numeric(victim_age)) %>% 
  filter(!is.na(victim_age)) %>% 
  filter(victim_race != "unknown") %>% 
  mutate(victim_race = ifelse(victim_race == "White", "white", "non-white")) %>% 
  mutate(victim_race = as.factor(victim_race)) %>% 
  mutate(victim_race = relevel(victim_race, ref = "white")) %>% 
  mutate(resolution = factor(ifelse(
    disposition %in% c("Closed without arrest", "Open/No arrest"), "unresolved", "resolved")))
```

After importing the data, I created a city_state variable. I excluded cities that have errors or do not report race. I converted age to numeric and removed NA age rows. I filtered out unknown race and recoded race as white or non-white, with white as the reference group. I removed unknown race because if the race is unknown, we cannot know if race is white or non-white. I recoded the disposition variavle as unresolved or resolved.

### Baltimore model

```{r baltimore fit}
baltimore_fit = homicides_df %>%
  filter(city_state == "Baltimore, MD") %>% 
  glm(resolution ~ victim_age + victim_race + victim_sex, data = ., family = binomial())
```

The above code saves a logistic regression to baltimore_glm. The model uses victim age, race, and sex to predict whether the case is unresolved.

```{r odds ratio}
baltimore_fit %>% broom::tidy(conf.int = TRUE) %>% 
  mutate(OR = exp(estimate),
         conf.low = exp(conf.low),
         conf.high = exp(conf.high)) %>% 
  select(term, OR, conf.low, conf.high) %>% 
  filter(term == "victim_racenon-white") %>% 
  knitr::kable(digits = 3)
```

The above table shows the estimate and confidence interval of the odds ratio for resolved vs unresolved homicides predicted by race, controling for age and sex. We can see that non-white victims are 2.27 times as likely as white victims to have their case unresolved. 

### Models for all cities

```{r all cities fit}
homicides_models = homicides_df %>% 
  group_by(city_state) %>% 
  nest() %>% # now we have a list col called data containing all the data for each city state
  mutate(model = map(data, ~broom::tidy(glm(resolution ~ victim_age + victim_race + victim_sex, data = ., family = binomial()), conf.int = TRUE))) %>%
  select(-data) %>% 
  unnest() %>%
  mutate(OR = exp(estimate),
         conf.low = exp(conf.low),
         conf.high = exp(conf.high)) %>% 
  select(city_state, term, OR, conf.low, conf.high) %>%
  filter(term == "victim_racenon-white")

homicides_models %>% knitr::kable(digits = 3)
```

The above code uses a map function to run the model that we used with baltimore on each city_state.

```{r all cities plot}
homicides_models %>% 
  mutate(city_state = forcats::fct_reorder(city_state, OR)) %>%
  ggplot(aes(x = city_state, y = OR)) + 
      geom_point() +
      geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
      labs(
        x = "City, State",
        y = "Odds Ratio",
        title = "Odds homicide remains unsolved if non-white compared to white") +
      theme_bw() +
      theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

The above plot shows that Boston is the US city with the largest discrepancy in homicide resolutions between white and non-white victims. In Boston, non-white victim homicides are 8.7 times as likely to remain unresolved compared to white victim homicides.

# Problem 2

### Load and tidy data

```{r load and tidy birthweight data}
birthweight_df = read_csv(file = "./data/birthweight.csv")

birthweight_df = birthweight_df %>% 
   mutate(
      babysex = as.factor(babysex),
      frace = as.factor(frace),
      malform = as.factor(malform),
      mrace = as.factor(mrace))
```

The code above loads the data and converts sex, mother's race, father's race, and birth malformation into factor variables.

```{r missing data}
birthweight_df %>% 
  is.na() %>% summary()
```

From the code above we see that there is no missing data

### Propose model

```{r models}
lin_mod1 = lm(bwt ~ mheight, data = birthweight_df)
lin_mod2 = lm(bwt ~ mheight + mrace, data = birthweight_df)
lin_mod3 = lm(bwt ~ mheight + mrace + momage, data = birthweight_df)
lin_mod4 = lm(bwt ~ mheight + mrace + momage + delwt, data = birthweight_df)

broom::tidy(lin_mod1)
broom::tidy(lin_mod2)
broom::tidy(lin_mod3)
broom::tidy(lin_mod4)
```

I decided to examine models with maternal characteristics. I simply added a new maternal variable into each successive model.


```{r training data}
cv_df = 
  crossv_mc(birthweight_df, 100)
```

The above code uses modelr to do 100 training/testing splits on the birthweight_df. 

```{r run models on training data}
cv_df = 
  cv_df %>% 
  mutate(lin_mod1 = map(train, ~lm(bwt ~ mheight, data = .x)),
         lin_mod2 = map(train, ~lm(bwt ~ mheight + mrace, data = .x)),
         lin_mod3 = map(train, ~lm(bwt ~ mheight + mrace + momage, data = .x)),
         lin_mod4 = map(train, ~lm(bwt ~ mheight + mrace + momage + delwt, data = .x))) %>% 
  mutate(rmse_lin1 = map2_dbl(lin_mod1, test, ~rmse(model = .x, data = .y)),
         rmse_lin2 = map2_dbl(lin_mod2, test, ~rmse(model = .x, data = .y)),
         rmse_lin3 = map2_dbl(lin_mod3, test, ~rmse(model = .x, data = .y)),
         rmse_lin4 = map2_dbl(lin_mod4, test, ~rmse(model = .x, data = .y)))
```

The above code fits the 4 proposed models and gets RMSEs

```{r proposed model plot}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

From the above plots, we see that the full model with mother's height, race, age, and weight was the best model because on average, it produced the lowest RMSEs when run with 100 training datasets.

### Plot residuals and predictions


```{r pred and resid plot}
resid = modelr::add_residuals(birthweight_df, lin_mod4)
resid_and_pred = modelr::add_predictions(resid, lin_mod4)

resid_and_pred %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  labs(
    title = "Model",
    x = "Predictions",
    y = "Residuals"
    ) 
```
Above is a plot of the proposed model residuals against fitted values. Points are clustered nicely around 0 and there is no odd pattern, which is good! A linear model seems appropriate for these data.

### Compare proposed model to Jeff's models

```{r compare to jeffs models, warning = FALSE}

cv_df2 = 
  crossv_mc(birthweight_df, 100)

cv_df2 = 
  cv_df2 %>% 
  mutate(lin_mod5 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         lin_mod6 = map(train, ~lm(bwt ~ blength*bhead*babysex, data = .x)),
         proposed_mod = map(train, ~lm(bwt ~ mheight + mrace + momage + delwt, data = .x)),
         combined_mod = map(train, ~lm(bwt ~ blength*bhead*babysex + mheight + mrace + momage + delwt, data = .x))) %>% 
  mutate(rmse_mod5 = map2_dbl(lin_mod5, test, ~rmse(model = .x, data = .y)),
         rmse_mod6 = map2_dbl(lin_mod6, test, ~rmse(model = .x, data = .y)),
         rmse_proposed = map2_dbl(proposed_mod, test, ~rmse(model = .x, data = .y)),
         rmse_combined = map2_dbl(combined_mod, test, ~rmse(model = .x, data = .y)))

cv_df2 %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

The same cross validation procedures outlined above were performed to compare my proposed model with Jeff's models. From the plot above we see that Jeff's best model with head circumference, length, sex, and all interactions (model 6) was better than my model (proposed model). However, when I combined my proposed model with Jeff's best model, the RMSE was lower than Jeff's best model (combined model).